{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = str(0)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras  # tf.keras\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.10.9 | packaged by Anaconda, Inc. | (main, Mar  1 2023, 18:18:15) [MSC v.1916 64 bit (AMD64)]\n",
      "matplotlib 3.7.0\n",
      "numpy 1.23.5\n",
      "pandas 1.5.3\n",
      "sklearn 1.2.1\n",
      "tensorflow 2.12.0\n",
      "keras.api._v2.keras 2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(\"python\", sys.version)\n",
    "for module in mpl, np, pd, sklearn, tf, keras:\n",
    "    print(module.__name__, module.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sys.version_info >= (3, 5) # Python ≥3.5 required\n",
    "assert tf.__version__ >= \"2.0\"    # TensorFlow ≥2.0 required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_utility import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100, 10) (1000, 1)\n",
      "[[[0.000e+00 1.000e+00 2.000e+00 ... 7.000e+00 8.000e+00 9.000e+00]\n",
      "  [1.000e+01 1.100e+01 1.200e+01 ... 1.700e+01 1.800e+01 1.900e+01]\n",
      "  [2.000e+01 2.100e+01 2.200e+01 ... 2.700e+01 2.800e+01 2.900e+01]\n",
      "  ...\n",
      "  [9.700e+02 9.710e+02 9.720e+02 ... 9.770e+02 9.780e+02 9.790e+02]\n",
      "  [9.800e+02 9.810e+02 9.820e+02 ... 9.870e+02 9.880e+02 9.890e+02]\n",
      "  [9.900e+02 9.910e+02 9.920e+02 ... 9.970e+02 9.980e+02 9.990e+02]]\n",
      "\n",
      " [[1.000e+03 1.001e+03 1.002e+03 ... 1.007e+03 1.008e+03 1.009e+03]\n",
      "  [1.010e+03 1.011e+03 1.012e+03 ... 1.017e+03 1.018e+03 1.019e+03]\n",
      "  [1.020e+03 1.021e+03 1.022e+03 ... 1.027e+03 1.028e+03 1.029e+03]\n",
      "  ...\n",
      "  [1.970e+03 1.971e+03 1.972e+03 ... 1.977e+03 1.978e+03 1.979e+03]\n",
      "  [1.980e+03 1.981e+03 1.982e+03 ... 1.987e+03 1.988e+03 1.989e+03]\n",
      "  [1.990e+03 1.991e+03 1.992e+03 ... 1.997e+03 1.998e+03 1.999e+03]]]\n"
     ]
    }
   ],
   "source": [
    "n_times = 1000; n_markets = 100; n_fields = 10\n",
    "Candles = [ [ [ time * n_markets * n_fields + market * n_fields + field for field in range(n_fields) ] for market in range(n_markets) ] for time in range(n_times)]\n",
    "Candles = np.array(Candles, dtype=np.float32)\n",
    "Times = np.array( range(Candles.shape[0]), dtype=Candles.dtype ) + 333\n",
    "Times = np.expand_dims(Times, axis=1)\n",
    "size_time = 1\n",
    "print(Candles.shape, Times.shape)   # time, market, field\n",
    "print(Candles[:2, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100, 10) (99,) (74,) (25,)\n",
      "[[[0.000e+00 1.000e+00 2.000e+00]\n",
      "  [1.000e+01 1.100e+01 1.200e+01]\n",
      "  [2.000e+01 2.100e+01 2.200e+01]]\n",
      "\n",
      " [[1.000e+03 1.001e+03 1.002e+03]\n",
      "  [1.010e+03 1.011e+03 1.012e+03]\n",
      "  [1.020e+03 1.021e+03 1.022e+03]]]\n",
      "[[[2021. 2022. 2023.]\n",
      "  [2031. 2032. 2033.]\n",
      "  [2041. 2042. 2043.]]\n",
      "\n",
      " [[3021. 3022. 3023.]\n",
      "  [3031. 3032. 3033.]\n",
      "  [3041. 3042. 3043.]]]\n",
      "9 9 1\n"
     ]
    }
   ],
   "source": [
    "Nx = 10\n",
    "Ny = 2\n",
    "Ns = 10\n",
    "\n",
    "sample_anchors = np.array(range(0, Candles.shape[0] - Nx - Ny + 1, Ns), dtype=np.int32)\n",
    "sample_anchores_t = sample_anchors[: sample_anchors.shape[0] * 3 // 4]\n",
    "sample_anchores_v = sample_anchors[sample_anchors.shape[0] * 3 // 4 :]\n",
    "print(Candles.shape, sample_anchors.shape, sample_anchores_t.shape, sample_anchores_v.shape)\n",
    "\n",
    "x_indices = ( (0, 1, 2), (0,1,2) )    # (market, field)\n",
    "y_indices = ( (2, 3, 4), (1,2,3) )    # (market, field). Currently must be the same size as x_indices.\n",
    "print(Candles[0:2][:, x_indices[0]][:, :, x_indices[1]])\n",
    "print(Candles[2:4][:, y_indices[0]][:, :, y_indices[1]])\n",
    "\n",
    "size_x = get_timepoint_size(x_indices)\n",
    "size_y = get_timepoint_size(y_indices)\n",
    "\n",
    "print(size_x, size_y, size_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100, 7)\n",
      "(1000, 100)\n",
      "100\n",
      "((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), (2, 3, 4, 5, 6))\n",
      "((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), (0, 1, 2, 3, 4))\n",
      "['market_49', 'market_72', 'market_71', 'market_70', 'market_69', 'market_68', 'market_67', 'market_66', 'market_65', 'market_64', 'market_63', 'market_62', 'market_61', 'market_60', 'market_59', 'market_58', 'market_57', 'market_56', 'market_55', 'market_54', 'market_53', 'market_52', 'market_73', 'market_51', 'market_74', 'market_76', 'market_97', 'market_96', 'market_95', 'market_94', 'market_93', 'market_92', 'market_91', 'market_90', 'market_89', 'market_88', 'market_87', 'market_86', 'market_85', 'market_84', 'market_83', 'market_82', 'market_81', 'market_80', 'market_79', 'market_78', 'market_77', 'market_75', 'market_50', 'market_99', 'market_48', 'market_21', 'market_20', 'market_19', 'market_18', 'market_17', 'market_16', 'market_15', 'market_14', 'market_13', 'market_12', 'market_11', 'market_10', 'market_9', 'market_8', 'market_7', 'market_6', 'market_5', 'market_4', 'market_3', 'market_2', 'market_1', 'market_22', 'market_23', 'market_24', 'market_25', 'market_47', 'market_46', 'market_45', 'market_44', 'market_43', 'market_42', 'market_41', 'market_40', 'market_39', 'market_38', 'market_98', 'market_37', 'market_35', 'market_34', 'market_33', 'market_32', 'market_31', 'market_30', 'market_29', 'market_28', 'market_27', 'market_26', 'market_36', 'market_0']\n",
      "['filed_2', 'filed_3', 'filed_4', 'filed_5', 'filed_6']\n",
      "['market_49', 'market_72', 'market_71', 'market_70', 'market_69', 'market_68', 'market_67', 'market_66', 'market_65', 'market_64', 'market_63', 'market_62', 'market_61', 'market_60', 'market_59', 'market_58', 'market_57', 'market_56', 'market_55', 'market_54', 'market_53', 'market_52', 'market_73', 'market_51', 'market_74', 'market_76', 'market_97', 'market_96', 'market_95', 'market_94', 'market_93', 'market_92', 'market_91', 'market_90', 'market_89', 'market_88', 'market_87', 'market_86', 'market_85', 'market_84', 'market_83', 'market_82', 'market_81', 'market_80', 'market_79', 'market_78', 'market_77', 'market_75', 'market_50', 'market_99', 'market_48', 'market_21', 'market_20', 'market_19', 'market_18', 'market_17', 'market_16', 'market_15', 'market_14', 'market_13', 'market_12', 'market_11', 'market_10', 'market_9', 'market_8', 'market_7', 'market_6', 'market_5', 'market_4', 'market_3', 'market_2', 'market_1', 'market_22', 'market_23', 'market_24', 'market_25', 'market_47', 'market_46', 'market_45', 'market_44', 'market_43', 'market_42', 'market_41', 'market_40', 'market_39', 'market_38', 'market_98', 'market_37', 'market_35', 'market_34', 'market_33', 'market_32', 'market_31', 'market_30', 'market_29', 'market_28', 'market_27', 'market_26', 'market_36', 'market_0']\n",
      "['filed_0', 'filed_1', 'filed_2', 'filed_3', 'filed_4']\n",
      "['market_49', 'market_72', 'market_71', 'market_70', 'market_69', 'market_68', 'market_67', 'market_66', 'market_65', 'market_64', 'market_63', 'market_62', 'market_61', 'market_60', 'market_59', 'market_58', 'market_57', 'market_56', 'market_55', 'market_54', 'market_53', 'market_52', 'market_73', 'market_51', 'market_74', 'market_76', 'market_97', 'market_96', 'market_95', 'market_94', 'market_93', 'market_92', 'market_91', 'market_90', 'market_89', 'market_88', 'market_87', 'market_86', 'market_85', 'market_84', 'market_83', 'market_82', 'market_81', 'market_80', 'market_79', 'market_78', 'market_77', 'market_75', 'market_50', 'market_99', 'market_48', 'market_21', 'market_20', 'market_19', 'market_18', 'market_17', 'market_16', 'market_15', 'market_14', 'market_13', 'market_12', 'market_11', 'market_10', 'market_9', 'market_8', 'market_7', 'market_6', 'market_5', 'market_4', 'market_3', 'market_2', 'market_1', 'market_22', 'market_23', 'market_24', 'market_25', 'market_47', 'market_46', 'market_45', 'market_44', 'market_43', 'market_42', 'market_41', 'market_40', 'market_39', 'market_38', 'market_98', 'market_37', 'market_35', 'market_34', 'market_33', 'market_32', 'market_31', 'market_30', 'market_29', 'market_28', 'market_27', 'market_26', 'market_36', 'market_0']\n",
      "['filed_0', 'filed_1', 'filed_2', 'filed_3', 'filed_4', 'filed_5', 'filed_6']\n",
      "['market_14', 'market_13', 'market_12', 'market_11', 'market_10', 'market_9', 'market_8', 'market_7', 'market_6', 'market_5', 'market_4', 'market_3', 'market_2']\n",
      "(58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70)\n",
      "100 100 13\n"
     ]
    }
   ],
   "source": [
    "# Dummy variables\n",
    "CandleMarks = Candles[:, :, 0]\n",
    "all_market_names = [ 'market_' + str(i) for i in range(Candles.shape[1])]\n",
    "all_field_names = [ 'filed_' + str(i) for i in range(Candles.shape[2])]\n",
    "min_true_candle_percent_x = 50\n",
    "chosen_fields_names_x = all_field_names[2:7]\n",
    "min_true_candle_percent_y = 50\n",
    "chosen_fields_names_y = all_field_names[0:5]\n",
    "target_market_names = all_market_names[2:15] #[0:1] # [1:2]\n",
    "tarket_market_top_percent = 15\n",
    "\n",
    "Candles, CandleMarks, all_market_names, x_indices, y_indices, \\\n",
    "chosen_market_names_x, chosen_field_names_x, chosen_market_names_y, chosen_field_names_y, \\\n",
    "chosen_market_names, chosen_field_names, \\\n",
    "target_markets_names, target_markets = \\\n",
    "get_formed_data( Candles, CandleMarks, all_market_names, all_field_names, \n",
    "        min_true_candle_percent_x, chosen_fields_names_x, min_true_candle_percent_y, chosen_fields_names_y,\n",
    "        target_market_names, tarket_market_top_percent\n",
    ")\n",
    "\n",
    "print(Candles.shape)\n",
    "print(CandleMarks.shape)\n",
    "print(len(all_market_names))\n",
    "print(x_indices)\n",
    "print(y_indices)\n",
    "print(chosen_market_names_x)\n",
    "print(chosen_field_names_x)\n",
    "print(chosen_market_names_y)\n",
    "print(chosen_field_names_y)\n",
    "print(chosen_market_names)\n",
    "print(chosen_field_names)\n",
    "print(target_markets_names)\n",
    "print(target_markets)\n",
    "print(len(chosen_market_names_x), len(chosen_market_names_y), len(target_markets_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37 13\n"
     ]
    }
   ],
   "source": [
    "Time_into_X = True\n",
    "Time_into_Y = False\n",
    "BatchSize = 2\n",
    "shuffle_batch = 10\n",
    "\n",
    "ds_train, ds_valid, dx, dy = \\\n",
    "get_datasets_2(\n",
    "    Candles, Time_into_X, Time_into_Y, Times, \n",
    "    sample_anchores_t, sample_anchores_v,\n",
    "    Nx, x_indices, Ny, y_indices, size_time, target_markets,\n",
    "    BatchSize, shuffle_batch, shuffle=True\n",
    ")\n",
    "\n",
    "print(len(ds_train), len(ds_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "5\n",
      "(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499)\n"
     ]
    }
   ],
   "source": [
    "non_target_markets_relative = [ y_indices[0].index(i) for i in y_indices[0] if i not in target_markets ]\n",
    "print(non_target_markets_relative)\n",
    "nFeaturesPerMarket = len(y_indices[1])\n",
    "print(nFeaturesPerMarket)\n",
    "all_ntmr = []\n",
    "for ntmr in non_target_markets_relative:\n",
    "    all_ntmr = all_ntmr + list(range(ntmr* nFeaturesPerMarket, (ntmr+1) * nFeaturesPerMarket, 1))\n",
    "non_target_features_relative = tuple(all_ntmr)\n",
    "print(non_target_features_relative)\n",
    "\n",
    "def anchor_to_sample(anchor): # This function is the bottle-neck of training speed.\n",
    "    x = np.reshape(Candles[anchor: anchor + Nx][:, x_indices[0]][:, :, x_indices[1]], (Nx, -1))\n",
    "    if Time_into_X is True:\n",
    "        assert Times is not None\n",
    "        x = np.concatenate((x, np.reshape(Times[anchor: anchor + Nx], (Nx, -1))), axis=1) # concat(x, x_time)\n",
    "\n",
    "    print('x.shape', x.shape, x_indices)\n",
    "\n",
    "    y = np.reshape(Candles[anchor + Nx: anchor + Nx + Ny][:, y_indices[0]][:, :, y_indices[1]], (Ny, -1))\n",
    "    print('y.shape', y.shape, y_indices)\n",
    "\n",
    "    if Time_into_X is True:\n",
    "        assert Times is not None\n",
    "        y_time = np.reshape(Times[anchor + Nx: anchor + Nx + Ny], (Ny, -1))\n",
    "        if Time_into_Y is not True: y_time[:] = 0.0\n",
    "        y = np.concatenate((y, y_time), axis=1)\n",
    "\n",
    "    x = np.pad(x, [[1,1], [0,0]], constant_values=0)   # (1 pre-pad: Start, 1 post-pad: End) on axis 0. (0 pre-pad, 0 post-pad) on axis 1.\n",
    "    z = y\n",
    "    y = np.pad(y, [[1,1], [0,0]], constant_values=0)\n",
    "\n",
    "    if x.shape[-1] % 2 != 0:\n",
    "        x = np.pad(x, [[0,0], [0,1]], constant_values=0) # (0 pre-pad: Start, 0 post-pad: End) on axis 0. (0 pre-pad, 1 post-pad) on axis 1.\n",
    "        y = np.pad(y, [[0,0], [0,1]], constant_values=0)\n",
    "\n",
    "    y_target = np.copy(y[1:])\n",
    "    print(y_target.shape)\n",
    "    y_target[:, non_target_features_relative] = 0.0\n",
    "\n",
    "    return x, y[:-1], y_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[4.900e+02 4.910e+02 4.920e+02 ... 4.940e+02 4.950e+02 4.960e+02]\n",
      "  [7.200e+02 7.210e+02 7.220e+02 ... 7.240e+02 7.250e+02 7.260e+02]\n",
      "  [7.100e+02 7.110e+02 7.120e+02 ... 7.140e+02 7.150e+02 7.160e+02]\n",
      "  ...\n",
      "  [2.600e+02 2.610e+02 2.620e+02 ... 2.640e+02 2.650e+02 2.660e+02]\n",
      "  [3.600e+02 3.610e+02 3.620e+02 ... 3.640e+02 3.650e+02 3.660e+02]\n",
      "  [0.000e+00 1.000e+00 2.000e+00 ... 4.000e+00 5.000e+00 6.000e+00]]\n",
      "\n",
      " [[1.490e+03 1.491e+03 1.492e+03 ... 1.494e+03 1.495e+03 1.496e+03]\n",
      "  [1.720e+03 1.721e+03 1.722e+03 ... 1.724e+03 1.725e+03 1.726e+03]\n",
      "  [1.710e+03 1.711e+03 1.712e+03 ... 1.714e+03 1.715e+03 1.716e+03]\n",
      "  ...\n",
      "  [1.260e+03 1.261e+03 1.262e+03 ... 1.264e+03 1.265e+03 1.266e+03]\n",
      "  [1.360e+03 1.361e+03 1.362e+03 ... 1.364e+03 1.365e+03 1.366e+03]\n",
      "  [1.000e+03 1.001e+03 1.002e+03 ... 1.004e+03 1.005e+03 1.006e+03]]\n",
      "\n",
      " [[2.490e+03 2.491e+03 2.492e+03 ... 2.494e+03 2.495e+03 2.496e+03]\n",
      "  [2.720e+03 2.721e+03 2.722e+03 ... 2.724e+03 2.725e+03 2.726e+03]\n",
      "  [2.710e+03 2.711e+03 2.712e+03 ... 2.714e+03 2.715e+03 2.716e+03]\n",
      "  ...\n",
      "  [2.260e+03 2.261e+03 2.262e+03 ... 2.264e+03 2.265e+03 2.266e+03]\n",
      "  [2.360e+03 2.361e+03 2.362e+03 ... 2.364e+03 2.365e+03 2.366e+03]\n",
      "  [2.000e+03 2.001e+03 2.002e+03 ... 2.004e+03 2.005e+03 2.006e+03]]\n",
      "\n",
      " [[3.490e+03 3.491e+03 3.492e+03 ... 3.494e+03 3.495e+03 3.496e+03]\n",
      "  [3.720e+03 3.721e+03 3.722e+03 ... 3.724e+03 3.725e+03 3.726e+03]\n",
      "  [3.710e+03 3.711e+03 3.712e+03 ... 3.714e+03 3.715e+03 3.716e+03]\n",
      "  ...\n",
      "  [3.260e+03 3.261e+03 3.262e+03 ... 3.264e+03 3.265e+03 3.266e+03]\n",
      "  [3.360e+03 3.361e+03 3.362e+03 ... 3.364e+03 3.365e+03 3.366e+03]\n",
      "  [3.000e+03 3.001e+03 3.002e+03 ... 3.004e+03 3.005e+03 3.006e+03]]]\n"
     ]
    }
   ],
   "source": [
    "print(Candles[:4, :, :]) # market order may be changed by argmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape (10, 501) ((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), (2, 3, 4, 5, 6))\n",
      "y.shape (2, 500) ((0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99), (0, 1, 2, 3, 4))\n",
      "(3, 502)\n",
      "(12, 502)\n",
      "(3, 502)\n",
      "(3, 502)\n"
     ]
    }
   ],
   "source": [
    "x, y, y_shift = anchor_to_sample(0)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(y_shift.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[492. 493. 494. 495. 496.]\n",
      "[722. 723. 724. 725. 726.]\n",
      "[712. 713. 714. 715. 716.]\n",
      "[702. 703. 704. 705. 706.]\n",
      "[692. 693. 694. 695. 696.]\n",
      "[682. 683. 684. 685. 686.]\n",
      "[672. 673. 674. 675. 676.]\n",
      "[662. 663. 664. 665. 666.]\n",
      "[652. 653. 654. 655. 656.]\n",
      "[642. 643. 644. 645. 646.]\n",
      "[632. 633. 634. 635. 636.]\n",
      "[622. 623. 624. 625. 626.]\n",
      "[612. 613. 614. 615. 616.]\n",
      "[602. 603. 604. 605. 606.]\n",
      "[592. 593. 594. 595. 596.]\n",
      "[582. 583. 584. 585. 586.]\n",
      "[572. 573. 574. 575. 576.]\n",
      "[562. 563. 564. 565. 566.]\n",
      "[552. 553. 554. 555. 556.]\n",
      "[542. 543. 544. 545. 546.]\n",
      "[532. 533. 534. 535. 536.]\n",
      "[522. 523. 524. 525. 526.]\n",
      "[732. 733. 734. 735. 736.]\n",
      "[512. 513. 514. 515. 516.]\n",
      "[742. 743. 744. 745. 746.]\n",
      "[762. 763. 764. 765. 766.]\n",
      "[972. 973. 974. 975. 976.]\n",
      "[962. 963. 964. 965. 966.]\n",
      "[952. 953. 954. 955. 956.]\n",
      "[942. 943. 944. 945. 946.]\n",
      "[932. 933. 934. 935. 936.]\n",
      "[922. 923. 924. 925. 926.]\n",
      "[912. 913. 914. 915. 916.]\n",
      "[902. 903. 904. 905. 906.]\n",
      "[892. 893. 894. 895. 896.]\n",
      "[882. 883. 884. 885. 886.]\n",
      "[872. 873. 874. 875. 876.]\n",
      "[862. 863. 864. 865. 866.]\n",
      "[852. 853. 854. 855. 856.]\n",
      "[842. 843. 844. 845. 846.]\n",
      "[832. 833. 834. 835. 836.]\n",
      "[822. 823. 824. 825. 826.]\n",
      "[812. 813. 814. 815. 816.]\n",
      "[802. 803. 804. 805. 806.]\n",
      "[792. 793. 794. 795. 796.]\n",
      "[782. 783. 784. 785. 786.]\n",
      "[772. 773. 774. 775. 776.]\n",
      "[752. 753. 754. 755. 756.]\n",
      "[502. 503. 504. 505. 506.]\n",
      "[992. 993. 994. 995. 996.]\n",
      "[482. 483. 484. 485. 486.]\n",
      "[212. 213. 214. 215. 216.]\n",
      "[202. 203. 204. 205. 206.]\n",
      "[192. 193. 194. 195. 196.]\n",
      "[182. 183. 184. 185. 186.]\n",
      "[172. 173. 174. 175. 176.]\n",
      "[162. 163. 164. 165. 166.]\n",
      "[152. 153. 154. 155. 156.]\n",
      "[142. 143. 144. 145. 146.]\n",
      "[132. 133. 134. 135. 136.]\n",
      "[122. 123. 124. 125. 126.]\n",
      "[112. 113. 114. 115. 116.]\n",
      "[102. 103. 104. 105. 106.]\n",
      "[92. 93. 94. 95. 96.]\n",
      "[82. 83. 84. 85. 86.]\n",
      "[72. 73. 74. 75. 76.]\n",
      "[62. 63. 64. 65. 66.]\n",
      "[52. 53. 54. 55. 56.]\n",
      "[42. 43. 44. 45. 46.]\n",
      "[32. 33. 34. 35. 36.]\n",
      "[22. 23. 24. 25. 26.]\n",
      "[12. 13. 14. 15. 16.]\n",
      "[222. 223. 224. 225. 226.]\n",
      "[232. 233. 234. 235. 236.]\n",
      "[242. 243. 244. 245. 246.]\n",
      "[252. 253. 254. 255. 256.]\n",
      "[472. 473. 474. 475. 476.]\n",
      "[462. 463. 464. 465. 466.]\n",
      "[452. 453. 454. 455. 456.]\n",
      "[442. 443. 444. 445. 446.]\n",
      "[432. 433. 434. 435. 436.]\n",
      "[422. 423. 424. 425. 426.]\n",
      "[412. 413. 414. 415. 416.]\n",
      "[402. 403. 404. 405. 406.]\n",
      "[392. 393. 394. 395. 396.]\n",
      "[382. 383. 384. 385. 386.]\n",
      "[982. 983. 984. 985. 986.]\n",
      "[372. 373. 374. 375. 376.]\n",
      "[352. 353. 354. 355. 356.]\n",
      "[342. 343. 344. 345. 346.]\n",
      "[332. 333. 334. 335. 336.]\n",
      "[322. 323. 324. 325. 326.]\n",
      "[312. 313. 314. 315. 316.]\n",
      "[302. 303. 304. 305. 306.]\n",
      "[292. 293. 294. 295. 296.]\n",
      "[282. 283. 284. 285. 286.]\n",
      "[272. 273. 274. 275. 276.]\n",
      "[262. 263. 264. 265. 266.]\n",
      "[362. 363. 364. 365. 366.]\n",
      "[2. 3. 4. 5. 6.]\n",
      "[333.   0.]\n",
      "[1492. 1493. 1494. 1495. 1496.]\n",
      "[1722. 1723. 1724. 1725. 1726.]\n",
      "[1712. 1713. 1714. 1715. 1716.]\n",
      "[1702. 1703. 1704. 1705. 1706.]\n",
      "[1692. 1693. 1694. 1695. 1696.]\n",
      "[1682. 1683. 1684. 1685. 1686.]\n",
      "[1672. 1673. 1674. 1675. 1676.]\n",
      "[1662. 1663. 1664. 1665. 1666.]\n",
      "[1652. 1653. 1654. 1655. 1656.]\n",
      "[1642. 1643. 1644. 1645. 1646.]\n",
      "[1632. 1633. 1634. 1635. 1636.]\n",
      "[1622. 1623. 1624. 1625. 1626.]\n",
      "[1612. 1613. 1614. 1615. 1616.]\n",
      "[1602. 1603. 1604. 1605. 1606.]\n",
      "[1592. 1593. 1594. 1595. 1596.]\n",
      "[1582. 1583. 1584. 1585. 1586.]\n",
      "[1572. 1573. 1574. 1575. 1576.]\n",
      "[1562. 1563. 1564. 1565. 1566.]\n",
      "[1552. 1553. 1554. 1555. 1556.]\n",
      "[1542. 1543. 1544. 1545. 1546.]\n",
      "[1532. 1533. 1534. 1535. 1536.]\n",
      "[1522. 1523. 1524. 1525. 1526.]\n",
      "[1732. 1733. 1734. 1735. 1736.]\n",
      "[1512. 1513. 1514. 1515. 1516.]\n",
      "[1742. 1743. 1744. 1745. 1746.]\n",
      "[1762. 1763. 1764. 1765. 1766.]\n",
      "[1972. 1973. 1974. 1975. 1976.]\n",
      "[1962. 1963. 1964. 1965. 1966.]\n",
      "[1952. 1953. 1954. 1955. 1956.]\n",
      "[1942. 1943. 1944. 1945. 1946.]\n",
      "[1932. 1933. 1934. 1935. 1936.]\n",
      "[1922. 1923. 1924. 1925. 1926.]\n",
      "[1912. 1913. 1914. 1915. 1916.]\n",
      "[1902. 1903. 1904. 1905. 1906.]\n",
      "[1892. 1893. 1894. 1895. 1896.]\n",
      "[1882. 1883. 1884. 1885. 1886.]\n",
      "[1872. 1873. 1874. 1875. 1876.]\n",
      "[1862. 1863. 1864. 1865. 1866.]\n",
      "[1852. 1853. 1854. 1855. 1856.]\n",
      "[1842. 1843. 1844. 1845. 1846.]\n",
      "[1832. 1833. 1834. 1835. 1836.]\n",
      "[1822. 1823. 1824. 1825. 1826.]\n",
      "[1812. 1813. 1814. 1815. 1816.]\n",
      "[1802. 1803. 1804. 1805. 1806.]\n",
      "[1792. 1793. 1794. 1795. 1796.]\n",
      "[1782. 1783. 1784. 1785. 1786.]\n",
      "[1772. 1773. 1774. 1775. 1776.]\n",
      "[1752. 1753. 1754. 1755. 1756.]\n",
      "[1502. 1503. 1504. 1505. 1506.]\n",
      "[1992. 1993. 1994. 1995. 1996.]\n",
      "[1482. 1483. 1484. 1485. 1486.]\n",
      "[1212. 1213. 1214. 1215. 1216.]\n",
      "[1202. 1203. 1204. 1205. 1206.]\n",
      "[1192. 1193. 1194. 1195. 1196.]\n",
      "[1182. 1183. 1184. 1185. 1186.]\n",
      "[1172. 1173. 1174. 1175. 1176.]\n",
      "[1162. 1163. 1164. 1165. 1166.]\n",
      "[1152. 1153. 1154. 1155. 1156.]\n",
      "[1142. 1143. 1144. 1145. 1146.]\n",
      "[1132. 1133. 1134. 1135. 1136.]\n",
      "[1122. 1123. 1124. 1125. 1126.]\n",
      "[1112. 1113. 1114. 1115. 1116.]\n",
      "[1102. 1103. 1104. 1105. 1106.]\n",
      "[1092. 1093. 1094. 1095. 1096.]\n",
      "[1082. 1083. 1084. 1085. 1086.]\n",
      "[1072. 1073. 1074. 1075. 1076.]\n",
      "[1062. 1063. 1064. 1065. 1066.]\n",
      "[1052. 1053. 1054. 1055. 1056.]\n",
      "[1042. 1043. 1044. 1045. 1046.]\n",
      "[1032. 1033. 1034. 1035. 1036.]\n",
      "[1022. 1023. 1024. 1025. 1026.]\n",
      "[1012. 1013. 1014. 1015. 1016.]\n",
      "[1222. 1223. 1224. 1225. 1226.]\n",
      "[1232. 1233. 1234. 1235. 1236.]\n",
      "[1242. 1243. 1244. 1245. 1246.]\n",
      "[1252. 1253. 1254. 1255. 1256.]\n",
      "[1472. 1473. 1474. 1475. 1476.]\n",
      "[1462. 1463. 1464. 1465. 1466.]\n",
      "[1452. 1453. 1454. 1455. 1456.]\n",
      "[1442. 1443. 1444. 1445. 1446.]\n",
      "[1432. 1433. 1434. 1435. 1436.]\n",
      "[1422. 1423. 1424. 1425. 1426.]\n",
      "[1412. 1413. 1414. 1415. 1416.]\n",
      "[1402. 1403. 1404. 1405. 1406.]\n",
      "[1392. 1393. 1394. 1395. 1396.]\n",
      "[1382. 1383. 1384. 1385. 1386.]\n",
      "[1982. 1983. 1984. 1985. 1986.]\n",
      "[1372. 1373. 1374. 1375. 1376.]\n",
      "[1352. 1353. 1354. 1355. 1356.]\n",
      "[1342. 1343. 1344. 1345. 1346.]\n",
      "[1332. 1333. 1334. 1335. 1336.]\n",
      "[1322. 1323. 1324. 1325. 1326.]\n",
      "[1312. 1313. 1314. 1315. 1316.]\n",
      "[1302. 1303. 1304. 1305. 1306.]\n",
      "[1292. 1293. 1294. 1295. 1296.]\n",
      "[1282. 1283. 1284. 1285. 1286.]\n",
      "[1272. 1273. 1274. 1275. 1276.]\n",
      "[1262. 1263. 1264. 1265. 1266.]\n",
      "[1362. 1363. 1364. 1365. 1366.]\n",
      "[1002. 1003. 1004. 1005. 1006.]\n",
      "[334.   0.]\n"
     ]
    }
   ],
   "source": [
    "assert x.shape[0] == Nx + 2\n",
    "\n",
    "seq = 0\n",
    "assert np.sum(x[seq]>0) == 0\n",
    "\n",
    "seq = 1\n",
    "batch = len(chosen_fields_names_x)\n",
    "for b in range(0, x.shape[1], batch):\n",
    "    print(x[seq][b: b + batch])\n",
    "assert x[seq][-1] == 0.0     # -1 for the odd-padding\n",
    "assert x[seq][-2] > 0     # time\n",
    "\n",
    "seq = 2\n",
    "batch = len(chosen_fields_names_x)\n",
    "for b in range(0, x.shape[1], batch):\n",
    "    print(x[seq][b: b + batch])\n",
    "assert x[seq][-1] == 0.0     # -1 for the odd-padding\n",
    "assert x[seq][-2] > 0     # time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10490. 10491. 10492. 10493. 10494.]\n",
      "[10720. 10721. 10722. 10723. 10724.]\n",
      "[10710. 10711. 10712. 10713. 10714.]\n",
      "[10700. 10701. 10702. 10703. 10704.]\n",
      "[10690. 10691. 10692. 10693. 10694.]\n",
      "[10680. 10681. 10682. 10683. 10684.]\n",
      "[10670. 10671. 10672. 10673. 10674.]\n",
      "[10660. 10661. 10662. 10663. 10664.]\n",
      "[10650. 10651. 10652. 10653. 10654.]\n",
      "[10640. 10641. 10642. 10643. 10644.]\n",
      "[10630. 10631. 10632. 10633. 10634.]\n",
      "[10620. 10621. 10622. 10623. 10624.]\n",
      "[10610. 10611. 10612. 10613. 10614.]\n",
      "[10600. 10601. 10602. 10603. 10604.]\n",
      "[10590. 10591. 10592. 10593. 10594.]\n",
      "[10580. 10581. 10582. 10583. 10584.]\n",
      "[10570. 10571. 10572. 10573. 10574.]\n",
      "[10560. 10561. 10562. 10563. 10564.]\n",
      "[10550. 10551. 10552. 10553. 10554.]\n",
      "[10540. 10541. 10542. 10543. 10544.]\n",
      "[10530. 10531. 10532. 10533. 10534.]\n",
      "[10520. 10521. 10522. 10523. 10524.]\n",
      "[10730. 10731. 10732. 10733. 10734.]\n",
      "[10510. 10511. 10512. 10513. 10514.]\n",
      "[10740. 10741. 10742. 10743. 10744.]\n",
      "[10760. 10761. 10762. 10763. 10764.]\n",
      "[10970. 10971. 10972. 10973. 10974.]\n",
      "[10960. 10961. 10962. 10963. 10964.]\n",
      "[10950. 10951. 10952. 10953. 10954.]\n",
      "[10940. 10941. 10942. 10943. 10944.]\n",
      "[10930. 10931. 10932. 10933. 10934.]\n",
      "[10920. 10921. 10922. 10923. 10924.]\n",
      "[10910. 10911. 10912. 10913. 10914.]\n",
      "[10900. 10901. 10902. 10903. 10904.]\n",
      "[10890. 10891. 10892. 10893. 10894.]\n",
      "[10880. 10881. 10882. 10883. 10884.]\n",
      "[10870. 10871. 10872. 10873. 10874.]\n",
      "[10860. 10861. 10862. 10863. 10864.]\n",
      "[10850. 10851. 10852. 10853. 10854.]\n",
      "[10840. 10841. 10842. 10843. 10844.]\n",
      "[10830. 10831. 10832. 10833. 10834.]\n",
      "[10820. 10821. 10822. 10823. 10824.]\n",
      "[10810. 10811. 10812. 10813. 10814.]\n",
      "[10800. 10801. 10802. 10803. 10804.]\n",
      "[10790. 10791. 10792. 10793. 10794.]\n",
      "[10780. 10781. 10782. 10783. 10784.]\n",
      "[10770. 10771. 10772. 10773. 10774.]\n",
      "[10750. 10751. 10752. 10753. 10754.]\n",
      "[10500. 10501. 10502. 10503. 10504.]\n",
      "[10990. 10991. 10992. 10993. 10994.]\n",
      "[10480. 10481. 10482. 10483. 10484.]\n",
      "[10210. 10211. 10212. 10213. 10214.]\n",
      "[10200. 10201. 10202. 10203. 10204.]\n",
      "[10190. 10191. 10192. 10193. 10194.]\n",
      "[10180. 10181. 10182. 10183. 10184.]\n",
      "[10170. 10171. 10172. 10173. 10174.]\n",
      "[10160. 10161. 10162. 10163. 10164.]\n",
      "[10150. 10151. 10152. 10153. 10154.]\n",
      "[10140. 10141. 10142. 10143. 10144.]\n",
      "[10130. 10131. 10132. 10133. 10134.]\n",
      "[10120. 10121. 10122. 10123. 10124.]\n",
      "[10110. 10111. 10112. 10113. 10114.]\n",
      "[10100. 10101. 10102. 10103. 10104.]\n",
      "[10090. 10091. 10092. 10093. 10094.]\n",
      "[10080. 10081. 10082. 10083. 10084.]\n",
      "[10070. 10071. 10072. 10073. 10074.]\n",
      "[10060. 10061. 10062. 10063. 10064.]\n",
      "[10050. 10051. 10052. 10053. 10054.]\n",
      "[10040. 10041. 10042. 10043. 10044.]\n",
      "[10030. 10031. 10032. 10033. 10034.]\n",
      "[10020. 10021. 10022. 10023. 10024.]\n",
      "[10010. 10011. 10012. 10013. 10014.]\n",
      "[10220. 10221. 10222. 10223. 10224.]\n",
      "[10230. 10231. 10232. 10233. 10234.]\n",
      "[10240. 10241. 10242. 10243. 10244.]\n",
      "[10250. 10251. 10252. 10253. 10254.]\n",
      "[10470. 10471. 10472. 10473. 10474.]\n",
      "[10460. 10461. 10462. 10463. 10464.]\n",
      "[10450. 10451. 10452. 10453. 10454.]\n",
      "[10440. 10441. 10442. 10443. 10444.]\n",
      "[10430. 10431. 10432. 10433. 10434.]\n",
      "[10420. 10421. 10422. 10423. 10424.]\n",
      "[10410. 10411. 10412. 10413. 10414.]\n",
      "[10400. 10401. 10402. 10403. 10404.]\n",
      "[10390. 10391. 10392. 10393. 10394.]\n",
      "[10380. 10381. 10382. 10383. 10384.]\n",
      "[10980. 10981. 10982. 10983. 10984.]\n",
      "[10370. 10371. 10372. 10373. 10374.]\n",
      "[10350. 10351. 10352. 10353. 10354.]\n",
      "[10340. 10341. 10342. 10343. 10344.]\n",
      "[10330. 10331. 10332. 10333. 10334.]\n",
      "[10320. 10321. 10322. 10323. 10324.]\n",
      "[10310. 10311. 10312. 10313. 10314.]\n",
      "[10300. 10301. 10302. 10303. 10304.]\n",
      "[10290. 10291. 10292. 10293. 10294.]\n",
      "[10280. 10281. 10282. 10283. 10284.]\n",
      "[10270. 10271. 10272. 10273. 10274.]\n",
      "[10260. 10261. 10262. 10263. 10264.]\n",
      "[10360. 10361. 10362. 10363. 10364.]\n",
      "[10000. 10001. 10002. 10003. 10004.]\n",
      "[0. 0.]\n",
      "[11490. 11491. 11492. 11493. 11494.]\n",
      "[11720. 11721. 11722. 11723. 11724.]\n",
      "[11710. 11711. 11712. 11713. 11714.]\n",
      "[11700. 11701. 11702. 11703. 11704.]\n",
      "[11690. 11691. 11692. 11693. 11694.]\n",
      "[11680. 11681. 11682. 11683. 11684.]\n",
      "[11670. 11671. 11672. 11673. 11674.]\n",
      "[11660. 11661. 11662. 11663. 11664.]\n",
      "[11650. 11651. 11652. 11653. 11654.]\n",
      "[11640. 11641. 11642. 11643. 11644.]\n",
      "[11630. 11631. 11632. 11633. 11634.]\n",
      "[11620. 11621. 11622. 11623. 11624.]\n",
      "[11610. 11611. 11612. 11613. 11614.]\n",
      "[11600. 11601. 11602. 11603. 11604.]\n",
      "[11590. 11591. 11592. 11593. 11594.]\n",
      "[11580. 11581. 11582. 11583. 11584.]\n",
      "[11570. 11571. 11572. 11573. 11574.]\n",
      "[11560. 11561. 11562. 11563. 11564.]\n",
      "[11550. 11551. 11552. 11553. 11554.]\n",
      "[11540. 11541. 11542. 11543. 11544.]\n",
      "[11530. 11531. 11532. 11533. 11534.]\n",
      "[11520. 11521. 11522. 11523. 11524.]\n",
      "[11730. 11731. 11732. 11733. 11734.]\n",
      "[11510. 11511. 11512. 11513. 11514.]\n",
      "[11740. 11741. 11742. 11743. 11744.]\n",
      "[11760. 11761. 11762. 11763. 11764.]\n",
      "[11970. 11971. 11972. 11973. 11974.]\n",
      "[11960. 11961. 11962. 11963. 11964.]\n",
      "[11950. 11951. 11952. 11953. 11954.]\n",
      "[11940. 11941. 11942. 11943. 11944.]\n",
      "[11930. 11931. 11932. 11933. 11934.]\n",
      "[11920. 11921. 11922. 11923. 11924.]\n",
      "[11910. 11911. 11912. 11913. 11914.]\n",
      "[11900. 11901. 11902. 11903. 11904.]\n",
      "[11890. 11891. 11892. 11893. 11894.]\n",
      "[11880. 11881. 11882. 11883. 11884.]\n",
      "[11870. 11871. 11872. 11873. 11874.]\n",
      "[11860. 11861. 11862. 11863. 11864.]\n",
      "[11850. 11851. 11852. 11853. 11854.]\n",
      "[11840. 11841. 11842. 11843. 11844.]\n",
      "[11830. 11831. 11832. 11833. 11834.]\n",
      "[11820. 11821. 11822. 11823. 11824.]\n",
      "[11810. 11811. 11812. 11813. 11814.]\n",
      "[11800. 11801. 11802. 11803. 11804.]\n",
      "[11790. 11791. 11792. 11793. 11794.]\n",
      "[11780. 11781. 11782. 11783. 11784.]\n",
      "[11770. 11771. 11772. 11773. 11774.]\n",
      "[11750. 11751. 11752. 11753. 11754.]\n",
      "[11500. 11501. 11502. 11503. 11504.]\n",
      "[11990. 11991. 11992. 11993. 11994.]\n",
      "[11480. 11481. 11482. 11483. 11484.]\n",
      "[11210. 11211. 11212. 11213. 11214.]\n",
      "[11200. 11201. 11202. 11203. 11204.]\n",
      "[11190. 11191. 11192. 11193. 11194.]\n",
      "[11180. 11181. 11182. 11183. 11184.]\n",
      "[11170. 11171. 11172. 11173. 11174.]\n",
      "[11160. 11161. 11162. 11163. 11164.]\n",
      "[11150. 11151. 11152. 11153. 11154.]\n",
      "[11140. 11141. 11142. 11143. 11144.]\n",
      "[11130. 11131. 11132. 11133. 11134.]\n",
      "[11120. 11121. 11122. 11123. 11124.]\n",
      "[11110. 11111. 11112. 11113. 11114.]\n",
      "[11100. 11101. 11102. 11103. 11104.]\n",
      "[11090. 11091. 11092. 11093. 11094.]\n",
      "[11080. 11081. 11082. 11083. 11084.]\n",
      "[11070. 11071. 11072. 11073. 11074.]\n",
      "[11060. 11061. 11062. 11063. 11064.]\n",
      "[11050. 11051. 11052. 11053. 11054.]\n",
      "[11040. 11041. 11042. 11043. 11044.]\n",
      "[11030. 11031. 11032. 11033. 11034.]\n",
      "[11020. 11021. 11022. 11023. 11024.]\n",
      "[11010. 11011. 11012. 11013. 11014.]\n",
      "[11220. 11221. 11222. 11223. 11224.]\n",
      "[11230. 11231. 11232. 11233. 11234.]\n",
      "[11240. 11241. 11242. 11243. 11244.]\n",
      "[11250. 11251. 11252. 11253. 11254.]\n",
      "[11470. 11471. 11472. 11473. 11474.]\n",
      "[11460. 11461. 11462. 11463. 11464.]\n",
      "[11450. 11451. 11452. 11453. 11454.]\n",
      "[11440. 11441. 11442. 11443. 11444.]\n",
      "[11430. 11431. 11432. 11433. 11434.]\n",
      "[11420. 11421. 11422. 11423. 11424.]\n",
      "[11410. 11411. 11412. 11413. 11414.]\n",
      "[11400. 11401. 11402. 11403. 11404.]\n",
      "[11390. 11391. 11392. 11393. 11394.]\n",
      "[11380. 11381. 11382. 11383. 11384.]\n",
      "[11980. 11981. 11982. 11983. 11984.]\n",
      "[11370. 11371. 11372. 11373. 11374.]\n",
      "[11350. 11351. 11352. 11353. 11354.]\n",
      "[11340. 11341. 11342. 11343. 11344.]\n",
      "[11330. 11331. 11332. 11333. 11334.]\n",
      "[11320. 11321. 11322. 11323. 11324.]\n",
      "[11310. 11311. 11312. 11313. 11314.]\n",
      "[11300. 11301. 11302. 11303. 11304.]\n",
      "[11290. 11291. 11292. 11293. 11294.]\n",
      "[11280. 11281. 11282. 11283. 11284.]\n",
      "[11270. 11271. 11272. 11273. 11274.]\n",
      "[11260. 11261. 11262. 11263. 11264.]\n",
      "[11360. 11361. 11362. 11363. 11364.]\n",
      "[11000. 11001. 11002. 11003. 11004.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "assert y.shape[0] == Ny + 1\n",
    "\n",
    "seq = 0\n",
    "assert np.sum(y[seq]>0) == 0\n",
    "\n",
    "seq = 1\n",
    "batch = len(chosen_fields_names_y)\n",
    "for b in range(0, y.shape[1], batch):\n",
    "    print(y[seq][b: b + batch])\n",
    "assert y[seq][-1] == 0.0     # -1 for the odd-padding\n",
    "assert y[seq][-2] == 0.0     # Time_into_y: False\n",
    "assert np.sum(y[seq]>0) != len(target_markets_names) * len(chosen_field_names_y)\n",
    "\n",
    "seq = 2\n",
    "batch = len(chosen_fields_names_y)\n",
    "for b in range(0, y.shape[1], batch):\n",
    "    print(y[seq][b: b + batch])\n",
    "assert y[seq][-1] == 0.0    # -1 for the odd-padding\n",
    "assert y[seq][-2] == 0.0    # Time_into_y: False\n",
    "assert np.sum(y[seq]>0) != len(target_markets_names) * len(chosen_field_names_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[10140. 10141. 10142. 10143. 10144.]\n",
      "[10130. 10131. 10132. 10133. 10134.]\n",
      "[10120. 10121. 10122. 10123. 10124.]\n",
      "[10110. 10111. 10112. 10113. 10114.]\n",
      "[10100. 10101. 10102. 10103. 10104.]\n",
      "[10090. 10091. 10092. 10093. 10094.]\n",
      "[10080. 10081. 10082. 10083. 10084.]\n",
      "[10070. 10071. 10072. 10073. 10074.]\n",
      "[10060. 10061. 10062. 10063. 10064.]\n",
      "[10050. 10051. 10052. 10053. 10054.]\n",
      "[10040. 10041. 10042. 10043. 10044.]\n",
      "[10030. 10031. 10032. 10033. 10034.]\n",
      "[10020. 10021. 10022. 10023. 10024.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[11140. 11141. 11142. 11143. 11144.]\n",
      "[11130. 11131. 11132. 11133. 11134.]\n",
      "[11120. 11121. 11122. 11123. 11124.]\n",
      "[11110. 11111. 11112. 11113. 11114.]\n",
      "[11100. 11101. 11102. 11103. 11104.]\n",
      "[11090. 11091. 11092. 11093. 11094.]\n",
      "[11080. 11081. 11082. 11083. 11084.]\n",
      "[11070. 11071. 11072. 11073. 11074.]\n",
      "[11060. 11061. 11062. 11063. 11064.]\n",
      "[11050. 11051. 11052. 11053. 11054.]\n",
      "[11040. 11041. 11042. 11043. 11044.]\n",
      "[11030. 11031. 11032. 11033. 11034.]\n",
      "[11020. 11021. 11022. 11023. 11024.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0.]\n",
      "[0. 0.]\n"
     ]
    }
   ],
   "source": [
    "assert y_shift.shape[0] == Ny + 1\n",
    "\n",
    "seq = 0\n",
    "batch = len(chosen_fields_names_y)\n",
    "for b in range(0, y_shift.shape[1], batch):\n",
    "    print(y_shift[seq][b: b + batch])\n",
    "assert y_shift[seq][-1] == 0.0     # -1 for the odd-padding\n",
    "assert y_shift[seq][-2] == 0.0     # Time_into_y: False\n",
    "assert np.sum(y_shift[seq]>0) == len(target_markets_names) * len(chosen_field_names_y)\n",
    "\n",
    "seq = 1\n",
    "batch = len(chosen_fields_names_y)\n",
    "for b in range(0, y.shape[1], batch):\n",
    "    print(y_shift[seq][b: b + batch])\n",
    "assert y_shift[seq][-1] == 0.0    # -1 for the odd-padding\n",
    "assert y_shift[seq][-2] == 0.0    # Time_into_y: False\n",
    "assert np.sum(y_shift[seq]>0) == len(target_markets_names) * len(chosen_field_names_y)\n",
    "\n",
    "seq = 2\n",
    "assert np.sum(y_shift[seq]>0) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_valid, dx, dy = \\\n",
    "get_datasets_2(\n",
    "    Candles, Time_into_X, Time_into_Y, Times, \n",
    "    sample_anchores_t, sample_anchores_v,\n",
    "    Nx, x_indices, Ny, y_indices, size_time, target_markets,\n",
    "    BatchSize, shuffle_batch, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((<tf.Tensor: shape=(2, 12, 502), dtype=float32, numpy=\n",
      "array([[[    0.,     0.,     0., ...,     0.,     0.,     0.],\n",
      "        [20492., 20493., 20494., ..., 20006.,   353.,     0.],\n",
      "        [21492., 21493., 21494., ..., 21006.,   354.,     0.],\n",
      "        ...,\n",
      "        [28492., 28493., 28494., ..., 28006.,   361.,     0.],\n",
      "        [29492., 29493., 29494., ..., 29006.,   362.,     0.],\n",
      "        [    0.,     0.,     0., ...,     0.,     0.,     0.]],\n",
      "\n",
      "       [[    0.,     0.,     0., ...,     0.,     0.,     0.],\n",
      "        [80492., 80493., 80494., ..., 80006.,   413.,     0.],\n",
      "        [81492., 81493., 81494., ..., 81006.,   414.,     0.],\n",
      "        ...,\n",
      "        [88492., 88493., 88494., ..., 88006.,   421.,     0.],\n",
      "        [89492., 89493., 89494., ..., 89006.,   422.,     0.],\n",
      "        [    0.,     0.,     0., ...,     0.,     0.,     0.]]],\n",
      "      dtype=float32)>, <tf.Tensor: shape=(2, 3, 502), dtype=float32, numpy=\n",
      "array([[[    0.,     0.,     0., ...,     0.,     0.,     0.],\n",
      "        [30490., 30491., 30492., ..., 30004.,     0.,     0.],\n",
      "        [31490., 31491., 31492., ..., 31004.,     0.,     0.]],\n",
      "\n",
      "       [[    0.,     0.,     0., ...,     0.,     0.,     0.],\n",
      "        [90490., 90491., 90492., ..., 90004.,     0.,     0.],\n",
      "        [91490., 91491., 91492., ..., 91004.,     0.,     0.]]],\n",
      "      dtype=float32)>), <tf.Tensor: shape=(2, 3, 502), dtype=float32, numpy=\n",
      "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]],\n",
      "\n",
      "       [[0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.],\n",
      "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "for elem in ds_train:\n",
    "    print(elem)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_utility import *\n",
    "# from test_trans import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = \"/mnt/data/Trading/\"\n",
    "\n",
    "data_model = \"mv03.200.5.60.15.12.1\"\n",
    "\n",
    "#===================================================================== Dataset\n",
    "\n",
    "Nx = 200 # ------------- test\n",
    "Ny = 5\n",
    "Ns = 5 #--------------------- test\n",
    "BatchSize = 64\n",
    "\n",
    "CandleFile = \"18-01-01-00-00-23-05-20-20-23-5m\"\n",
    "SmallSigma = 1\n",
    "LargeSigma = 30\n",
    "eFreeNoLog = True\n",
    "\n",
    "shuffle_batch = 50  # Keep it small to speed up model loading.\n",
    "\n",
    "dir_candles = os.path.join(dir_data, \"Candles\")\n",
    "\n",
    "min_true_candle_percent_x = 60\n",
    "chosen_markets_x = []\n",
    "chosen_fields_names_x = ['ClosePrice'] #, 'BaseVolume']\n",
    "min_true_candle_percent_y = 60\n",
    "assert min_true_candle_percent_x == min_true_candle_percent_y\n",
    "chosen_markets_y = []\n",
    "chosen_fields_names_y = ['ClosePrice']\n",
    "\n",
    "target_market_names = None\n",
    "# target_market_names = ['NEOUSDT', 'LTCUSDT', 'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'QTUMUSDT', 'ADAUSDT', 'XRPUSDT']\n",
    "tarket_market_top_percent = 15\n",
    "\n",
    "Standardization = True\n",
    "Kill_Irregulars = True  # ----------------- pls implement it\n",
    "Time_into_X = True\n",
    "Time_into_Y = False #\n",
    "eFreeNoPlot = True\n",
    "\n",
    "#======================================================================== Model\n",
    "\n",
    "Num_Layers = 12 # Wow\n",
    "Num_Heads = 1   # As we have a single GPU, and we want to a exhaustic attention.\n",
    "Factor_FF = 4\n",
    "repComplexity = 12  # Wower\n",
    "Dropout_Rate = 0.1\n",
    "\n",
    "dir_Checkpoint = os.path.join(dir_data, \"Checkpoints\")\n",
    "checkpoint_filepath = os.path.join(dir_Checkpoint, data_model)\n",
    "dir_CSVLogs = os.path.join(dir_data, \"CSVLogs\")\n",
    "csvLogger_filepath = os.path.join(dir_CSVLogs, data_model)\n",
    "\n",
    "#======================================================================== Train\n",
    "\n",
    "Epochs_Initial = 5000\n",
    "HuberThreshold = 1.0\n",
    "Checkpoint_Monitor = \"val_loss\"\n",
    "EarlyStopping_Min_Monitor = \"val_loss\"\n",
    "EarlyStopping_Patience = 30\n",
    "\n",
    "Optimizer = \"adam\"\n",
    "Learning_Rate = 0.0001  # default: 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(gpus)\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            # tf.config.experimental.set_virtual_device_configuration(\n",
    "            #     gpu,[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)]) # why 5120?\n",
    "            # logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            # print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "mirrored_strategy = None\n",
    "if len(gpus) > 1: \n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "    Learning_Rate = Learning_Rate * len(gpus) * 3 / 4\n",
    "\n",
    "# tf.config.experimental.set_virtual_device_configuration(\n",
    "#     gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upgrade_file(path):\n",
    "    with open(path, \"+tw\") as f:\n",
    "        f.write(\"# Sorry, the content is removed.\")\n",
    "        f.write(\"\\n# Please ask Mike for the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = [dir_data, dir_candles, dir_Checkpoint, dir_CSVLogs]\n",
    "for folder in folders:\n",
    "    if not os.path.isdir(folder):\n",
    "        os.mkdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================== Load candle data into 'table' with shape of (time, markets, 10 fields) ====================\n",
    "Candles = np.load( os.path.join( dir_candles, \"table-\" + CandleFile + \".npy\") )\n",
    "Candles = np.swapaxes(Candles, 0, 1)\n",
    "Candles = Candles.astype(np.float32)    # Ugly, just confirm.\n",
    "print(\"Candles: {}\".format(Candles.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market = 5\n",
    "Show_Price_Volume_10(Candles[:, market, :], 1, 1, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Event_Free_Learning_Scheme_10(Candles[:, market, :], 3, 30, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================== Delete 7 candle fields from 'Candles'. ====================\n",
    "# Candles.shape becomes (time, markets, ['ClosePrice', 'BaseVolume', 'BuyerBaseVolume'] )\n",
    "\n",
    "CandleMarks = Candles[:, :, 9] # keep it for later use\n",
    "Candles = np.delete(Candles, [0, 1, 2, 5, 6, 8, 9], axis = 2) # delete Open, High, Low, qVolume, #Trades, bQVolume, CandleMarks\n",
    "all_field_names = ['ClosePrice', 'BaseVolume', 'BuyerBaseVolume']\n",
    "\n",
    "assert (~np.isfinite(Candles)).any() == False\n",
    "\n",
    "table_markets = []\n",
    "with open( os.path.join( dir_candles, \"reports-\" + CandleFile + \".json\"), \"r\") as f:\n",
    "    reports = json.loads(f.read())\n",
    "print(reports[:2])\n",
    "\n",
    "all_market_names = [ s[0: s.find(':')] for s in reports if 'Success' in s ]\n",
    "assert Candles.shape[1] == len(all_market_names)\n",
    "print(Candles.shape, len(all_market_names), all_market_names[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Candles, CandleMarks, all_market_names, x_indices, y_indices, \\\n",
    "chosen_market_names_x, chosen_field_names_x, chosen_market_names_y, chosen_field_names_y, \\\n",
    "chosen_market_names, chosen_field_names, \\\n",
    "target_markets_names, target_markets = \\\n",
    "get_formed_data( Candles, CandleMarks, all_market_names, all_field_names, \n",
    "        min_true_candle_percent_x, chosen_fields_names_x, min_true_candle_percent_y, chosen_fields_names_y,\n",
    "        target_market_names, tarket_market_top_percent\n",
    ")\n",
    "\n",
    "print(Candles.shape)\n",
    "print(CandleMarks.shape)\n",
    "print(len(all_market_names))\n",
    "print(x_indices)\n",
    "print(y_indices)\n",
    "print(chosen_market_names_x)\n",
    "print(chosen_field_names_x)\n",
    "print(chosen_market_names_y)\n",
    "print(chosen_field_names_y)\n",
    "print(chosen_market_names)\n",
    "print(chosen_field_names)\n",
    "print(target_markets_names)\n",
    "print(target_markets)\n",
    "print(len(chosen_market_names_x), len(chosen_market_names_y), len(target_markets_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_ts, interval_s, timestamps_abs = get_timestamps_2(CandleFile, Candles.shape[0])\n",
    "print(start_ts, interval_s, timestamps_abs.shape, timestamps_abs[:3])\n",
    "\n",
    "Times = get_time_features(timestamps_abs)\n",
    "Times = Times.astype(Candles.dtype)\n",
    "size_time = Times.shape[1]\n",
    "\n",
    "assert Candles.shape[0] == Times.shape[0]\n",
    "print(Candles.shape, Times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================== Generate event-free data into Data ====================\n",
    "# Data loses heading items.\n",
    "# Do it before: Permute Data in time\n",
    "\n",
    "alpha = 3; beta = 3 # beta is used in 'get_eFree_with_plot'. Ugly coupling.\n",
    "event_free_data_loss = 3 * ( alpha * SmallSigma + LargeSigma)\n",
    "eFree = np.zeros( (Candles.shape[0] - event_free_data_loss, len(chosen_market_names), len(chosen_field_names)), dtype = Candles.dtype )\n",
    "\n",
    "for market in range(Candles.shape[1]):\n",
    "    for field in range(Candles.shape[2]):\n",
    "        sSigma = SmallSigma\n",
    "        if all_field_names[field] == 'BaseVolume': sSigma = SmallSigma * alpha\n",
    "        P, maP, logP, log_maP, event, eventFree = \\\n",
    "        get_eFree_with_plot(all_market_names[market], all_field_names[field], Candles[:, market, field], sSigma,\n",
    "                            LargeSigma, Candles.shape[0] - event_free_data_loss, noPlot=eFreeNoPlot, noLog=eFreeNoLog)\n",
    "        assert Candles.shape[0] - event_free_data_loss == eventFree.shape[0]\n",
    "        eventFree = eventFree.astype(Candles.dtype)\n",
    "        Candles[event_free_data_loss:, market, field] = eventFree\n",
    "\n",
    "Candles = Candles[event_free_data_loss:]\n",
    "Times = Times[event_free_data_loss:]\n",
    "assert Candles.shape[0] == Times.shape[0]\n",
    "\n",
    "print(Candles.shape, Times.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Standard = None\n",
    "\n",
    "if Standardization:\n",
    "    Candles, Standard = standardize_2(Candles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,3))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Features are custom-standardized\" if Standardization else \"Features are not standardized\")\n",
    "for market in range(Candles.shape[1]):\n",
    "    for field in range(Candles.shape[2]):\n",
    "        ax.plot(Candles[:, market, field], label = \"{} @ {}\".format(all_field_names[field], all_market_names[market][:-len('USDT')]))\n",
    "ax.legend(loc = 'upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_anchores_t, sample_anchores_v = get_sample_anchors_2(Candles, Nx, Ny, Ns)\n",
    "print(sample_anchores_t.shape, sample_anchores_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, ds_valid, dx, dy = \\\n",
    "get_datasets_2(\n",
    "    Candles, Time_into_X, Time_into_Y, Times, \n",
    "    sample_anchores_t, sample_anchores_v,\n",
    "    Nx, x_indices, Ny, y_indices, size_time, target_markets,\n",
    "    BatchSize, shuffle_batch, shuffle=(len(gpus)<=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ds_train.take(1)\n",
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = None\n",
    "\n",
    "if mirrored_strategy is None:\n",
    "    model = build_model_2(\n",
    "        dx, dy, Num_Layers, Num_Heads, Factor_FF, repComplexity, Dropout_Rate,\n",
    "        HuberThreshold, Optimizer, Learning_Rate\n",
    "    )\n",
    "else:\n",
    "    with mirrored_strategy.scope():\n",
    "        model = build_model_2(\n",
    "            dx, dy, Num_Layers, Num_Heads, Factor_FF, repComplexity, Dropout_Rate,\n",
    "            HuberThreshold, Optimizer, Learning_Rate\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = get_callbacks(\n",
    "    checkpoint_filepath, Checkpoint_Monitor, \n",
    "    csvLogger_filepath, \n",
    "    EarlyStopping_Min_Monitor, EarlyStopping_Patience\n",
    ")\n",
    "\n",
    "try:\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "except:\n",
    "    print(\"Failed to load a checkpoint\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train, # x and y_true\n",
    "    validation_data=ds_valid,\n",
    "    epochs=1, #Epochs_Initial,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train, # x and y_true\n",
    "    validation_data=ds_valid,\n",
    "    epochs=20, #Epochs_Initial,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ('loss', 'val_loss', 'mTA', 'val_mTA')\n",
    "plot_csv_log_history(csvLogger_filepath, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train, # x and y_true\n",
    "    validation_data=ds_valid,\n",
    "    epochs=50, #Epochs_Initial,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ('loss', 'val_loss', 'mTA', 'val_mTA')\n",
    "plot_csv_log_history(csvLogger_filepath, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train, # x and y_true\n",
    "    validation_data=ds_valid,\n",
    "    epochs=500, #Epochs_Initial,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ('loss', 'val_loss', 'mTA', 'val_mTA')\n",
    "plot_csv_log_history(csvLogger_filepath, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train, # x and y_true\n",
    "    validation_data=ds_valid,\n",
    "    epochs=500, #Epochs_Initial,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ('loss', 'val_loss', 'mTA', 'val_mTA')\n",
    "plot_csv_log_history(csvLogger_filepath, columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
