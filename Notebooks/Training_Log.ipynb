{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NB21 was enhanced with the following code, over NB20, and showed dramatically reduced losses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/3\n",
    "2023-05-25 19:40:17.275237: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-25 19:40:18.546347: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "618/618 [==============================] - 194s 277ms/step - loss: 29198790.0000 - mean_squared_error: 29198790.0000 - val_loss: 28408572.0000 - val_mean_squared_error: 28408572.0000\n",
    "Epoch 2/3\n",
    "618/618 [==============================] - 174s 277ms/step - loss: 28434302.0000 - mean_squared_error: 28434302.0000 - val_loss: 28311176.0000 - val_mean_squared_error: 28311176.0000\n",
    "Epoch 3/3\n",
    "618/618 [==============================] - 167s 265ms/step - loss: 28419544.0000 - mean_squared_error: 28419544.0000 - val_loss: 28259174.0000 - val_mean_squared_error: 28259174.0000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB21\n",
    "- Enhanced with 'logarithm + smoothen', which transformes both X and Y data.\n",
    "- Shifted the loss range to a smaller one.\n",
    "- We have to investigate the seemingly successful NB21 and NB31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmize + Smoothen\n",
    "smallSigma = 1\n",
    "largeSigma = 30\n",
    "\n",
    "head_data_loss = 3 * (smallSigma + largeSigma)\n",
    "eFree = np.zeros( (Data.shape[0] - head_data_loss, len(chosen_markets), len(chosen_fields)), dtype = np.float32 )\n",
    "\n",
    "for market in chosen_markets:\n",
    "    for field in chosen_fields:\n",
    "        P, maP, logP, log_maP, event, eventFree = \\\n",
    "        get_plot_log_feature(markets[market], enFields[field], Data[:, market, field], smallSigma, largeSigma, Data.shape[0] - head_data_loss, NoChart = True)\n",
    "        Data[head_data_loss:, market, field] = eventFree\n",
    "\n",
    "Data = Data[head_data_loss: ]\n",
    "\n",
    "print(Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/100\n",
    "2023-05-25 22:40:56.585019: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-25 22:40:57.861933: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "Output exceeds the size limit. Open the full output data in a text editor618/618 [==============================] - 195s 286ms/step - loss: 0.0330 - mean_squared_error: 0.0034 - val_loss: 9.0767e-04 - val_mean_squared_error: 0.0037\n",
    "Epoch 2/100\n",
    "618/618 [==============================] - 177s 282ms/step - loss: 7.1860e-04 - mean_squared_error: 0.0034 - val_loss: 7.0616e-04 - val_mean_squared_error: 0.0037\n",
    "Epoch 3/100\n",
    "618/618 [==============================] - 178s 285ms/step - loss: 6.8946e-04 - mean_squared_error: 0.0034 - val_loss: 7.0529e-04 - val_mean_squared_error: 0.0037\n",
    "Epoch 4/100\n",
    "618/618 [==============================] - 177s 283ms/step - loss: 6.8942e-04 - mean_squared_error: 0.0034 - val_loss: 7.0573e-04 - val_mean_squared_error: 0.0037\n",
    "Epoch 5/100\n",
    "618/618 [==============================] - 177s 283ms/step - loss: 6.8910e-04 - mean_squared_error: 0.0034 - val_loss: 7.0552e-04 - val_mean_squared_error: 0.0037"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/5\n",
    "2023-05-27 05:33:45.215406: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-27 05:33:46.502970: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "618/618 [==============================] - 184s 269ms/step - loss: 0.4824 - mean_squared_error: 0.7445 - val_loss: 0.3167 - val_mean_squared_error: 0.7626\n",
    "Epoch 2/5\n",
    "618/618 [==============================] - 167s 264ms/step - loss: 0.2327 - mean_squared_error: 0.7384 - val_loss: 0.1714 - val_mean_squared_error: 0.7622\n",
    "Epoch 3/5\n",
    "618/618 [==============================] - 157s 247ms/step - loss: 0.1374 - mean_squared_error: 0.7383 - val_loss: 0.1123 - val_mean_squared_error: 0.7622\n",
    "Epoch 4/5\n",
    "618/618 [==============================] - 170s 266ms/step - loss: 0.0977 - mean_squared_error: 0.7383 - val_loss: 0.0871 - val_mean_squared_error: 0.7623\n",
    "Epoch 5/5\n",
    "618/618 [==============================] - 167s 264ms/step - loss: 0.0804 - mean_squared_error: 0.7383 - val_loss: 0.0758 - val_mean_squared_error: 0.7622\n",
    "\n",
    "\n",
    "Epoch 1/5\n",
    "618/618 [==============================] - 161s 254ms/step - loss: 0.0725 - mean_squared_error: 0.7383 - val_loss: 0.0705 - val_mean_squared_error: 0.7622\n",
    "Epoch 2/5\n",
    "618/618 [==============================] - 166s 257ms/step - loss: 0.0687 - mean_squared_error: 0.7383 - val_loss: 0.0677 - val_mean_squared_error: 0.7622\n",
    "Epoch 3/5\n",
    "618/618 [==============================] - 166s 262ms/step - loss: 0.0667 - mean_squared_error: 0.7383 - val_loss: 0.0663 - val_mean_squared_error: 0.7622\n",
    "Epoch 4/5\n",
    "618/618 [==============================] - 167s 265ms/step - loss: 0.0656 - mean_squared_error: 0.7383 - val_loss: 0.0656 - val_mean_squared_error: 0.7622\n",
    "Epoch 5/5\n",
    "618/618 [==============================] - 168s 264ms/step - loss: 0.0651 - mean_squared_error: 0.7382 - val_loss: 0.0653 - val_mean_squared_error: 0.7622\n",
    "\n",
    "\n",
    "Epoch 1/5\n",
    "618/618 [==============================] - 166s 261ms/step - loss: 0.0649 - mean_squared_error: 0.7382 - val_loss: 0.0651 - val_mean_squared_error: 0.7622\n",
    "Epoch 2/5\n",
    "618/618 [==============================] - 163s 253ms/step - loss: 0.0648 - mean_squared_error: 0.7383 - val_loss: 0.0650 - val_mean_squared_error: 0.7622\n",
    "Epoch 3/5\n",
    "618/618 [==============================] - 168s 266ms/step - loss: 0.0647 - mean_squared_error: 0.7383 - val_loss: 0.0650 - val_mean_squared_error: 0.7622\n",
    "Epoch 4/5\n",
    "618/618 [==============================] - 168s 265ms/step - loss: 0.0647 - mean_squared_error: 0.7383 - val_loss: 0.0650 - val_mean_squared_error: 0.7622\n",
    "Epoch 5/5\n",
    "618/618 [==============================] - 159s 250ms/step - loss: 0.0647 - mean_squared_error: 0.7382 - val_loss: 0.0650 - val_mean_squared_error: 0.7622"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB29\n",
    "- first to introduce BatchNormalization between every layers.\n",
    "- Initial loss was rather larger than before.\n",
    "- But many epochs later, it began to catch up with NB28."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/15\n",
    "2023-05-27 06:26:41.431269: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-27 06:26:42.716711: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "618/618 [==============================] - 197s 285ms/step - loss: 0.6738 - mean_squared_error: 0.8584 - val_loss: 0.5978 - val_mean_squared_error: 0.7714\n",
    "\n",
    "... ... ...\n",
    "\n",
    "Epoch 15/15\n",
    "Epoch 5/5\n",
    "618/618 [==============================] - 176s 279ms/step - loss: 0.0654 - mean_squared_error: 0.7386 - val_loss: 0.0661 - val_mean_squared_error: 0.7641"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB30 \n",
    "- Failed to reproduce NB21, as shown in the following cell, because it has the \"standardization\" part, unlike NB21.\n",
    "- Find with \"TRY 21\", for what cells were added to NB29 for from NB30, in order to reproduce NB21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/5\n",
    "2023-05-27 08:30:32.486292: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-27 08:30:33.767349: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "618/618 [==============================] - 196s 285ms/step - loss: 0.2818 - mean_squared_error: 0.7197 - val_loss: 0.2364 - val_mean_squared_error: 0.7226\n",
    "Epoch 2/5\n",
    "618/618 [==============================] - 186s 294ms/step - loss: 0.2310 - mean_squared_error: 0.7190 - val_loss: 0.2289 - val_mean_squared_error: 0.7227\n",
    "Epoch 3/5\n",
    "618/618 [==============================] - 180s 286ms/step - loss: 0.2282 - mean_squared_error: 0.7190 - val_loss: 0.2282 - val_mean_squared_error: 0.7226\n",
    "Epoch 4/5\n",
    "618/618 [==============================] - 177s 279ms/step - loss: 0.2279 - mean_squared_error: 0.7190 - val_loss: 0.2281 - val_mean_squared_error: 0.7225\n",
    "Epoch 5/5\n",
    "618/618 [==============================] - 176s 279ms/step - loss: 0.2279 - mean_squared_error: 0.7190 - val_loss: 0.2281 - val_mean_squared_error: 0.7225"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB31 \n",
    "- succeeded to reproduce NB21, as shown in the following cell, only by removing the \"standardization\" part from NB30.\n",
    "- NB31 keeps \"TRY 21\" cells.\n",
    "- We have to investigate the seemingly successful NB21 and NB31.\n",
    "- If it's a true success, then we need to find out why the removal of \"standardiation\" contributes to reduce losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/5\n",
    "2023-05-27 08:55:23.746663: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-27 08:55:25.032882: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "618/618 [==============================] - 204s 290ms/step - loss: 0.0321 - mean_squared_error: 0.0036 - val_loss: 7.5261e-04 - val_mean_squared_error: 0.0022\n",
    "Epoch 2/5\n",
    "618/618 [==============================] - 179s 282ms/step - loss: 7.2928e-04 - mean_squared_error: 0.0036 - val_loss: 5.9348e-04 - val_mean_squared_error: 0.0022\n",
    "Epoch 3/5\n",
    "618/618 [==============================] - 179s 283ms/step - loss: 7.0681e-04 - mean_squared_error: 0.0036 - val_loss: 5.9278e-04 - val_mean_squared_error: 0.0022\n",
    "Epoch 4/5\n",
    "618/618 [==============================] - 201s 317ms/step - loss: 7.0670e-04 - mean_squared_error: 0.0036 - val_loss: 5.9294e-04 - val_mean_squared_error: 0.0022\n",
    "Epoch 5/5\n",
    "618/618 [==============================] - 185s 293ms/step - loss: 7.0654e-04 - mean_squared_error: 0.0036 - val_loss: 5.9251e-04 - val_mean_squared_error: 0.0022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB32\n",
    "- Reuse datasets generated by NB31\n",
    "- Remove NB21's 'build_model' and restore NB30's 'build_model, instead, which uses 'BatchNormalization' layer everywhere possible.\n",
    "- The 50th epoch, where learning acually stopped: - 180s 283ms/step - loss: 7.4420e-04 - mean_squared_error: 0.0036 - val_loss: 6.3788e-04 - val_mean_squared_error: 0.0022\n",
    "- During the whole 50 epochs, learning was steady and smooth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1\n",
    "2023-05-27 10:13:56.356905: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-27 10:13:57.600543: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "618/618 [==============================] - 198s 286ms/step - loss: 0.2860 - mean_squared_error: 0.1858 - val_loss: 0.2115 - val_mean_squared_error: 0.0348\n",
    "\n",
    "... ... ...\n",
    "\n",
    "Epoch 50/50\n",
    "618/618 [==============================] - 180s 283ms/step - loss: 7.4420e-04 - mean_squared_error: 0.0036 - val_loss: 6.3788e-04 - val_mean_squared_error: 0.0022"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The backgdound of the seemingly successful NB21 and NB31\n",
    "- where price is event-freed and standardization was skipped,\n",
    "\n",
    "- EventFree = log(ma(Price)) - MA(log(ma(Price))), where ma is moving average with a small sigma m and MA is with a larger sigma M.\n",
    "- EventFree is essentially logP - MA(logP), if m == 0, and represents the local vibration of logP.\n",
    "- The distribution of EventFree must follow N(0, sigma).\n",
    "    - sigma is small is M is small.\n",
    "    - sigma is small if P is steady.\n",
    "\n",
    "- As EventFree were a very small valuse, and as both X and Y come from EventFree, the losses became very small, even though there was BatchNormalization layers between hidden layers.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My mistake\n",
    "\n",
    "### I should have kept the sequence Data[:] in every sample.\n",
    "- k-th sample = { x = Data[k*Ns: k*Ns+Nx, chosen_markets_x, chosen_fileds_x], t = Data[k x Ns + Nx : m x Ns + Nx + Ny, chosen_markets_y, chosen_fileds_y] }\n",
    "### Shuffling/permuting should have been over samples, but not over the time slots inisde a sample.\n",
    "### All NBs through upto NB32 are wrong. Nevertheless, the losses were decreading for many epochs in some NBs. FUNNY.\n",
    "\n",
    "### We will need to create and split a file-streamed, shuffled tf dataset, of unknown size, into train_set and valid_set, before batching and prefetching them.  Possible?\n",
    "- We cannot simply create the dataset as a np array, because it would be of a huge size. (I once thought of this and forgt soon.)\n",
    "\n",
    "### Aha! let's permute and split the list of sample anchors.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose a large MA.\n",
    "- Let FreeEvent cross the zero axis over 10 times in a sample (A sample has Nx time slots). We will need a small MA.\n",
    "- Let FreeEvent large enough to ... We will need a large MA."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB33\n",
    "- **Ny changes from 10 to 5, to give less burden to fit.**\n",
    "- Chosen_markets_x and chosen_markets_y change from the (arbitrary short) 21 markets to selected 16 markets, to give more burden to fit?\n",
    "\n",
    "- Great, almost the same result as NB32."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Epoch 1/100\n",
    "2023-05-27 12:58:24.865842: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-27 12:58:26.134800: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "Output exceeds the size limit. Open the full output data in a text editor618/618 [==============================] - 178s 244ms/step - loss: 0.3775 - mean_squared_error: 0.1352 - val_loss: 0.3116 - val_mean_squared_error: 0.0160\n",
    "... ... ...\n",
    "Epoch 50/100\n",
    "618/618 [==============================] - 161s 253ms/step - loss: 8.0969e-04 - mean_squared_error: 0.0024 - val_loss: 8.2062e-04 - val_mean_squared_error: 0.0025"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB34\n",
    "- Fixs the mistake of shuffling time spots in samples, rather than samples.\n",
    "- Adds a BatchNorm layer just after the Input layer, while keeping the 'standardization' blocked.\n",
    "- Ns changes from 10 to 5 to generate many similar samples.\n",
    "- Ny changes from 10 to 5 to relieve the model from fitting complexity.\n",
    "- Shuffle_batch changes from 300 to 500, for better shuffle quality.\n",
    "- **Expected to have much smaller losses**, than NB33, because the time slots are now not shuffled, random things but are true stories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/30\n",
    "2023-05-28 12:48:31.803400: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-28 12:48:33.044246: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "1236/1236 [==============================] - 335s 247ms/step - loss: 0.3151 - mean_squared_error: 0.0793 - val_loss: 0.2658 - val_mean_squared_error: 0.0045\n",
    "... ... ...\n",
    "Epoch 11/30\n",
    "1236/1236 [==============================] - 311s 246ms/step - loss: 0.0011 - mean_squared_error: 0.0019 - val_loss: 9.1360e-04 - val_mean_squared_error: 0.0026\n",
    "... ... ...\n",
    "Epoch 29/30\n",
    "1236/1236 [==============================] - 326s 258ms/step - loss: 3.9925e-04 - mean_squared_error: 0.0017 - val_loss: 0.0021 - val_mean_squared_error: 0.0058"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB35\n",
    "- Only change: Standardize, both X and Y.\n",
    "- **Expected to have much larger losses**, than NB34, because Y are larger values than its original. 100X or so.\n",
    "- The losses will allow us to estimate the precision of prediction, because Y now follows known distribution N(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/30\n",
    "2023-05-28 23:08:33.289294: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-28 23:08:34.558840: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "1236/1236 [==============================] - 332s 247ms/step - loss: 0.3744 - mean_squared_error: 0.7822 - val_loss: 0.3313 - val_mean_squared_error: 0.7380\n",
    "Epoch 2/30\n",
    "1236/1236 [==============================] - 308s 244ms/step - loss: 0.2989 - mean_squared_error: 0.6430 - val_loss: 0.2671 - val_mean_squared_error: 0.6712\n",
    "... ... ...\n",
    "Epoch 30/30\n",
    "1236/1236 [==============================] - 304s 241ms/step - loss: 0.0316 - mean_squared_error: 0.3606 - val_loss: 0.0345 - val_mean_squared_error: 0.4426"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB36\n",
    "- **Ny changes fro 5 to 8**\n",
    "- The number of Markets_y changes from 16 to 10, instead.\n",
    "- Losses are of the same level as NB35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch 1/30\n",
    "2023-05-29 02:07:16.130300: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 29005 of 32000\n",
    "2023-05-29 02:07:16.752098: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
    "2023-05-29 02:07:17.684369: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8200\n",
    "2023-05-29 02:07:18.934558: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
    "1236/1236 [==============================] - 336s 247ms/step - loss: 0.3851 - mean_squared_error: 0.8408 - val_loss: 0.3451 - val_mean_squared_error: 0.7361\n",
    "Epoch 2/30\n",
    "1236/1236 [==============================] - 307s 243ms/step - loss: 0.3145 - mean_squared_error: 0.6877 - val_loss: 0.2858 - val_mean_squared_error: 0.6420\n",
    "... ... ...\n",
    "Epoch 30/30\n",
    "1236/1236 [==============================] - 308s 245ms/step - loss: 0.0361 - mean_squared_error: 0.3244 - val_loss: 0.0354 - val_mean_squared_error: 0.3159"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB37\n",
    "- Calls get_plot_log_feature_no_log, instead of get_plot_log_feature\n",
    "- What will happen to losses? Will it prove that log NN works?\n",
    "- log NN will be superior only when prices and volumes interact as inputs to NNs. Prices and volumes can not be naturally added/subtracted between themselves.\n",
    "    - Our prices are like: 2000 USDT / ETH, 25000 USDT / BTC. \n",
    "    - Can they be added/subtracted to give a meaningful dimension? No.\n",
    "    - Can tehy be multiplied/divided to give a meaningful dimension? Yes.\n",
    "- While the Hubor losses are similar to that of NB36, MSE losses are 10% smaller. A sign that log NN works?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB38\n",
    "- loss changes to MeanAbsoluteError, from Huber, to accelerate equally on small errors.\n",
    "- Restore get_plot_log_feature calls.\n",
    "- Keep standardization.\n",
    "- **Ny changes back to 5.** (Note we are based on 5-min candles. We aim at predicting 30-min future.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB39\n",
    "- Call get_plot_log_feature_no_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB40\n",
    "- Call get_plot_log_feature_no_log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB41, with Time added\n",
    "- Add Time to X.\n",
    "    - hourly = np.sin( 2 * np.pi / (60*60) * timestamps_abs )\n",
    "    - daily = np.sin( 2 * np.pi / (60*60*24) * timestamps_abs )\n",
    "    - weekly = np.sin( 2 * np.pi / (60*60*24*7) * timestamps_abs )\n",
    "    - yearly = np.sin( 2 * np.pi / (60*60*24*365) * timestamps_abs )\n",
    "- Change loss from MeanAbsoluteError back to MeanSquareError.\n",
    "- Change to 1-hour candles, accidently."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB42, with Time added\n",
    "- Back to 5-min candles.\n",
    "- Back to learning_rate=0.001 from 0.0001\n",
    "- on vm2, expected to be finished at 05 am June 6.\n",
    "- Nx = 700\n",
    "- Ny = 11\n",
    "- Ns = 5\n",
    "- Trainable params: 986,520\n",
    "\n",
    "- Very unstable loss convergence."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NB43, with Time added\n",
    "- on vm3.\n",
    "- Nx = 700\n",
    "- Ny = 5\n",
    "- Ns = 3\n",
    "- The model has more layers. \n",
    "- Trainable params: 208,440\n",
    "\n",
    "- Expected to he less unstable. Seems that a bit.\n",
    "- Ns = 3 is too small. Go back to 5.\n",
    "- Add more markets to enrich x.\n",
    "- Increase the number of file readers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "- Change the model to a RNN-based encoder-decoder model.\n",
    "- Change again to attention-based encoder-decoder model.\n",
    "- Add skip connection\n",
    "- Check what happens to losses if we don't convert to log.\n",
    "- Integrate with time features\n",
    "- Log, with combination of price and volume."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
